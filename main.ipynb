{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.optimize import least_squares\n",
    "from tomlkit import boolean\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor():\n",
    "    def __init__(self, data_folder:str, scaling_factor:float):\n",
    "        # Load camera intrinsic parameters\n",
    "        with open(data_folder + '\\\\calib.txt') as f:\n",
    "            self.camera_matrix = np.array(list((map(lambda x:list(map(lambda x:float(x), x.strip().split(' '))), f.read().split('\\n')))))\n",
    "            self.image_paths = []\n",
    "        \n",
    "        # Load the images\n",
    "        for img_file in sorted(os.listdir(data_folder)):\n",
    "            if img_file.endswith('.jpg') or img_file.endswith('.png'):\n",
    "                self.image_paths.append(os.path.join(data_folder, img_file))\n",
    "        \n",
    "        self.current_path = os.getcwd()\n",
    "        self.scale_factor = scaling_factor\n",
    "        self.apply_scaling()\n",
    "\n",
    "    def apply_scaling(self) -> None:\n",
    "        '''\n",
    "        Apply scaling to the camera intrinsic parameters based on the scale factor\n",
    "        '''\n",
    "        self.camera_matrix[0, 0] /= self.scale_factor\n",
    "        self.camera_matrix[1, 1] /= self.scale_factor\n",
    "        self.camera_matrix[0, 2] /= self.scale_factor\n",
    "        self.camera_matrix[1, 2] /= self.scale_factor\n",
    "    \n",
    "    def downscale_image(self, image):\n",
    "        for _ in range(1, int(self.scale_factor / 2) + 1):\n",
    "            image = cv2.pyrDown(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureFromMotion():\n",
    "    def __init__(self, data_folder:str, scaling_factor:float = 2.0) -> None:\n",
    "        self.image_processor = ImageProcessor(data_folder, scaling_factor)\n",
    "\n",
    "    def triangulate_points(self, points_2d_1, points_2d_2, proj_matrix_1, proj_matrix_2) -> tuple:\n",
    "        point_cloud = cv2.triangulatePoints(points_2d_1, points_2d_2, proj_matrix_1.T, proj_matrix_2.T)\n",
    "        return proj_matrix_1.T, proj_matrix_2.T, (point_cloud / point_cloud[3])\n",
    "\n",
    "    def find_pose(self, object_points, image_points, intrinsic_matrix, dist_coeffs, rotation_vector, initial) -> tuple:\n",
    "        if initial == 1:\n",
    "            object_points = object_points[:, 0, :]\n",
    "            image_points = image_points.T\n",
    "            rotation_vector = rotation_vector.T\n",
    "\n",
    "        _, rot_vector_est, tran_vector, inliers = cv2.solvePnPRansac(object_points, image_points, intrinsic_matrix, dist_coeffs, cv2.SOLVEPNP_ITERATIVE)\n",
    "        rotation_matrix, _ = cv2.Rodrigues(rot_vector_est)\n",
    "\n",
    "        if inliers is not None:\n",
    "            image_points = image_points[inliers[:, 0]]\n",
    "            object_points = object_points[inliers[:, 0]]\n",
    "            rotation_vector = rotation_vector[inliers[:, 0]]\n",
    "\n",
    "        return rotation_matrix, tran_vector, image_points, object_points, rotation_vector\n",
    "\n",
    "    def compute_reprojection_error(self, object_points, image_points, transformation_matrix, intrinsic_matrix, homogenity) -> tuple:\n",
    "        rotation_matrix = transformation_matrix[:3, :3]\n",
    "        translation_vector = transformation_matrix[:3, 3]\n",
    "        rotation_vector, _ = cv2.Rodrigues(rotation_matrix)\n",
    "\n",
    "        if homogenity == 1:\n",
    "            object_points = cv2.convertPointsFromHomogeneous(object_points.T)\n",
    "\n",
    "        projected_image_points, _ = cv2.projectPoints(object_points, rotation_vector, translation_vector, intrinsic_matrix, None)\n",
    "        projected_image_points = np.float32(projected_image_points[:, 0, :])\n",
    "        total_error = cv2.norm(projected_image_points, np.float32(image_points.T) if homogenity == 1 else np.float32(image_points), cv2.NORM_L2)\n",
    "\n",
    "        return total_error / len(projected_image_points), object_points\n",
    "\n",
    "    def compute_optimal_reprojection_error(self, object_points) -> np.array:\n",
    "        transformation_matrix = object_points[0:12].reshape((3, 4))\n",
    "        intrinsic_matrix = object_points[12:21].reshape((3, 3))\n",
    "        remaining_len = int(len(object_points[21:]) * 0.4)\n",
    "        p = object_points[21:21 + remaining_len].reshape((2, int(remaining_len / 2))).T\n",
    "        object_points = object_points[21 + remaining_len:].reshape((int(len(object_points[21 + remaining_len:]) / 3), 3))\n",
    "        rotation_matrix = transformation_matrix[:3, :3]\n",
    "        translation_vector = transformation_matrix[:3, 3]\n",
    "        rotation_vector, _ = cv2.Rodrigues(rotation_matrix)\n",
    "        projected_image_points, _ = cv2.projectPoints(object_points, rotation_vector, translation_vector, intrinsic_matrix, None)\n",
    "        projected_image_points = projected_image_points[:, 0, :] \n",
    "        errors = [(p[idx] - projected_image_points[idx]) ** 2 for idx in range(len(p))]\n",
    "        return np.array(errors).ravel() / len(p)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BundleAdjustmentUtility():\n",
    "    def bundle_adjust(self, object_points, optim_values, transformation_matrix_new, intrinsic_matrix, reprojection_error) -> tuple:\n",
    "        opt_variables = np.hstack((transformation_matrix_new.ravel(), intrinsic_matrix.ravel()))\n",
    "        opt_variables = np.hstack((opt_variables, optim_values.ravel()))\n",
    "        opt_variables = np.hstack((opt_variables, object_points.ravel()))\n",
    "\n",
    "        corrected_values = least_squares(self.compute_optimal_reprojection_error, opt_variables, gtol=reprojection_error).x\n",
    "        intrinsic_matrix = corrected_values[12:21].reshape((3, 3))\n",
    "        remaining_len = int(len(corrected_values[21:]) * 0.4)\n",
    "        return (\n",
    "            corrected_values[21 + remaining_len:].reshape((int(len(corrected_values[21 + remaining_len:]) / 3), 3)),\n",
    "            corrected_values[21:21 + remaining_len].reshape((2, int(remaining_len / 2))).T,\n",
    "            corrected_values[0:12].reshape((3, 4))\n",
    "        )\n",
    "\n",
    "    def export_to_ply(self, path, point_cloud, colors) -> None:\n",
    "        out_points = point_cloud.reshape(-1, 3) * 200\n",
    "        out_colors = colors.reshape(-1, 3)\n",
    "        verts = np.hstack([out_points, out_colors])\n",
    "\n",
    "        mean = np.mean(verts[:, :3], axis=0)\n",
    "        scaled_verts = verts[:, :3] - mean\n",
    "        dist = np.sqrt(scaled_verts[:, 0] ** 2 + scaled_verts[:, 1] ** 2 + scaled_verts[:, 2] ** 2)\n",
    "        idx = np.where(dist < np.mean(dist) + 300)\n",
    "        verts = verts[idx]\n",
    "        \n",
    "        ply_header = '''ply\n",
    "            format ascii 1.0\n",
    "            element vertex %(vert_num)d\n",
    "            property float x\n",
    "            property float y\n",
    "            property float z\n",
    "            property uchar blue\n",
    "            property uchar green\n",
    "            property uchar red\n",
    "            end_header\n",
    "            '''\n",
    "        with open(path + '\\\\point_clouds\\\\' + self.image_processor.image_paths[0].split('\\\\')[-2] + '.ply', 'w') as f:\n",
    "            f.write(ply_header % dict(vert_num=len(verts)))\n",
    "            np.savetxt(f, verts, '%f %f %f %d %d %d')\n",
    "\n",
    "    def find_common_points(self, points_1, points_2, points_3) -> tuple:\n",
    "        common_points_1 = []\n",
    "        common_points_2 = []\n",
    "\n",
    "        for i in range(points_1.shape[0]):\n",
    "            matching_indices = np.where(np.all(points_2 == points_1[i, :], axis=1))\n",
    "            if matching_indices[0].size != 0:\n",
    "                common_points_1.append(i)\n",
    "                common_points_2.append(matching_indices[0][0])\n",
    "\n",
    "        mask_array_1 = np.ma.array(points_2, mask=False)\n",
    "        mask_array_1.mask[common_points_2] = True\n",
    "        mask_array_1 = mask_array_1.compressed().reshape(-1, 2)\n",
    "\n",
    "        mask_array_2 = np.ma.array(points_3, mask=False)\n",
    "        mask_array_2.mask[common_points_2] = True\n",
    "        mask_array_2 = mask_array_2.compressed().reshape(-1, 2)\n",
    "\n",
    "        return np.array(common_points_1), np.array(common_points_2), mask_array_1, mask_array_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StructureFromMotionPipeline():\n",
    "    def find_features(self, image_0, image_1) -> tuple:\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        key_points_0, desc_0 = sift.detectAndCompute(cv2.cvtColor(image_0, cv2.COLOR_BGR2GRAY), None)\n",
    "        key_points_1, desc_1 = sift.detectAndCompute(cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(desc_0, desc_1, k=2)\n",
    "        feature = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.70 * n.distance:\n",
    "                feature.append(m)\n",
    "\n",
    "        return np.float32([key_points_0[m.queryIdx].pt for m in feature]), np.float32([key_points_1[m.trainIdx].pt for m in feature])\n",
    "\n",
    "    def process(self, enable_bundle_adjustment:boolean=False):\n",
    "        cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "        pose_array = self.image_processor.camera_matrix.ravel()\n",
    "        transform_matrix_0 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "        transform_matrix_1 = np.empty((3, 4))\n",
    "    \n",
    "        pose_0 = np.matmul(self.image_processor.camera_matrix, transform_matrix_0)\n",
    "        pose_1 = np.empty((3, 4)) \n",
    "        total_points = np.zeros((1, 3))\n",
    "        total_colors = np.zeros((1, 3))\n",
    "\n",
    "        image_0 = self.image_processor.downscale_image(cv2.imread(self.image_processor.image_paths[0]))\n",
    "        image_1 = self.image_processor.downscale_image(cv2.imread(self.image_processor.image_paths[1]))\n",
    "\n",
    "        feature_0, feature_1 = self.find_features(image_0, image_1)\n",
    "\n",
    "        essential_matrix, em_mask = cv2.findEssentialMat(feature_0, feature_1, self.image_processor.camera_matrix, method=cv2.RANSAC, prob=0.999, threshold=0.4, mask=None)\n",
    "        feature_0 = feature_0[em_mask.ravel() == 1]\n",
    "        feature_1 = feature_1[em_mask.ravel() == 1]\n",
    "\n",
    "        _, rot_matrix, tran_matrix, em_mask = cv2.recoverPose(essential_matrix, feature_0, feature_1, self.image_processor.camera_matrix)\n",
    "        feature_0 = feature_0[em_mask.ravel() > 0]\n",
    "        feature_1 = feature_1[em_mask.ravel() > 0]\n",
    "        transform_matrix_1[:3, :3] = np.matmul(rot_matrix, transform_matrix_0[:3, :3])\n",
    "        transform_matrix_1[:3, 3] = transform_matrix_0[:3, 3] + np.matmul(transform_matrix_0[:3, :3], tran_matrix.ravel())\n",
    "\n",
    "        pose_1 = np.matmul(self.image_processor.camera_matrix, transform_matrix_1)\n",
    "\n",
    "        feature_0, feature_1, points_3d = self.structure_from_motion.triangulate_points(pose_0, pose_1, feature_0, feature_1)\n",
    "        error, points_3d = self.structure_from_motion.compute_reprojection_error(points_3d, feature_1, transform_matrix_1, self.image_processor.camera_matrix, homogenity = 1)\n",
    "        print(\"REPROJECTION ERROR: \", error)\n",
    "        _, _, feature_1, points_3d, _ = self.structure_from_motion.find_pose(points_3d, feature_1, self.image_processor.camera_matrix, np.zeros((5, 1), dtype=np.float32), feature_0, initial=1)\n",
    "\n",
    "        total_images = len(self.image_processor.image_paths) - 2 \n",
    "        pose_array = np.hstack((np.hstack((pose_array, pose_0.ravel())), pose_1.ravel()))\n",
    "\n",
    "        threshold = 0.5\n",
    "        for i in tqdm(range(total_images)):\n",
    "            image_2 = self.image_processor.downscale_image(cv2.imread(self.image_processor.image_paths[i + 2]))\n",
    "            features_cur, features_2 = self.find_features(image_1, image_2)\n",
    "\n",
    "            if i != 0:\n",
    "                feature_0, feature_1, points_3d = self.structure_from_motion.triangulate_points(pose_0, pose_1, feature_0, feature_1)\n",
    "                feature_1 = feature_1.T\n",
    "                points_3d = cv2.convertPointsFromHomogeneous(points_3d.T)\n",
    "                points_3d = points_3d[:, 0, :]\n",
    "            \n",
    "            cm_points_0, cm_points_1, cm_mask_0, cm_mask_1 = self.structure_from_motion.find_common_points(feature_1, features_cur, features_2)\n",
    "            cm_points_2 = features_2[cm_points_1]\n",
    "            cm_points_cur = features_cur[cm_points_1]\n",
    "\n",
    "            rot_matrix, tran_matrix, cm_points_2, points_3d, cm_points_cur = self.structure_from_motion.find_pose(points_3d[cm_points_0], cm_points_2, self.image_processor.camera_matrix, np.zeros((5, 1), dtype=np.float32), cm_points_cur, initial = 0)\n",
    "            transform_matrix_1 = np.hstack((rot_matrix, tran_matrix))\n",
    "            pose_2 = np.matmul(self.image_processor.camera_matrix, transform_matrix_1)\n",
    "\n",
    "            error, points_3d = self.structure_from_motion.compute_reprojection_error(points_3d, cm_points_2, transform_matrix_1, self.image_processor.camera_matrix, homogenity = 0)\n",
    "        \n",
    "            cm_mask_0, cm_mask_1, points_3d = self.structure_from_motion.triangulate_points(pose_1, pose_2, cm_mask_0, cm_mask_1)\n",
    "            error, points_3d = self.structure_from_motion.compute_reprojection_error(points_3d, cm_mask_1, transform_matrix_1, self.image_processor.camera_matrix, homogenity = 1)\n",
    "            print(\"Reprojection Error: \", error)\n",
    "            pose_array = np.hstack((pose_array, pose_2.ravel()))\n",
    "\n",
    "            if enable_bundle_adjustment:\n",
    "                points_3d, cm_mask_1, transform_matrix_1 = self.structure_from_motion.bundle_adjustment(points_3d, cm_mask_1, transform_matrix_1, self.image_processor.camera_matrix, threshold)\n",
    "                pose_2 = np.matmul(self.image_processor.camera_matrix, transform_matrix_1)\n",
    "                error, points_3d = self.structure_from_motion.compute_reprojection_error(points_3d, cm_mask_1, transform_matrix_1, self.image_processor.camera_matrix, homogenity = 0)\n",
    "                print(\"Bundle Adjusted error: \",error)\n",
    "                total_points = np.vstack((total_points, points_3d))\n",
    "                points_left = np.array(cm_mask_1, dtype=np.int32)\n",
    "                color_vector = np.array([image_2[l[1], l[0]] for l in points_left])\n",
    "                total_colors = np.vstack((total_colors, color_vector))\n",
    "            else:\n",
    "                total_points = np.vstack((total_points, points_3d[:, 0, :]))\n",
    "                points_left = np.array(cm_mask_1, dtype=np.int32)\n",
    "                color_vector = np.array([image_2[l[1], l[0]] for l in points_left.T])\n",
    "                total_colors = np.vstack((total_colors, color_vector)) \n",
    "\n",
    "            transform_matrix_0 = np.copy(transform_matrix_1)\n",
    "            pose_0 = np.copy(pose_1)\n",
    "            plt.scatter(i, error)\n",
    "            plt.pause(0.05)\n",
    "\n",
    "            image_0 = np.copy(image_1)\n",
    "            image_1 = np.copy(image_2)\n",
    "            feature_0 = np.copy(features_cur)\n",
    "            feature_1 = np.copy(features_2)\n",
    "            pose_1 = np.copy(pose_2)\n",
    "            cv2.imshow(self.image_processor.image_paths[0].split('\\\\')[-2], image_2)\n",
    "            if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "                break\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(\"Saving .ply file\")\n",
    "        print(total_points.shape, total_colors.shape)\n",
    "        self.structure_from_motion.export_to_ply(self.image_processor.path, total_points, total_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    sfm_pipeline = StructureFromMotionPipeline()\n",
    "    sfm_pipeline.process()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
