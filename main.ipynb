{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibration_matrix(calib_file):\n",
    "    with open(calib_file) as f:\n",
    "        lines = f.readlines()\n",
    "        calib_matrix = np.array([list(map(float, line.strip().split())) for line in lines])\n",
    "        return calib_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def downscale_image(image, factor):\n",
    "    for _ in range(int(factor / 2)):\n",
    "        image = cv2.pyrDown(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_common_points(image_points_1, image_points_2):\n",
    "    common_points_1 = []\n",
    "    common_points_2 = []\n",
    "\n",
    "    for i, point_1 in enumerate(image_points_1):\n",
    "        for j, point_2 in enumerate(image_points_2):\n",
    "            if np.array_equal(point_1, point_2):\n",
    "                common_points_1.append(i)\n",
    "                common_points_2.append(j)\n",
    "\n",
    "    return np.array(common_points_1), np.array(common_points_2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(img_dir, downscale_factor=2.0, enable_bundle_adjustment=False):\n",
    "    image_list = sorted([image for image in os.listdir(img_dir) if image.lower().endswith('.jpg') or image.lower().endswith('.png')])\n",
    "\n",
    "    if len(image_list) < 2:\n",
    "        print(\"Insufficient images for processing.\")\n",
    "        return\n",
    "\n",
    "    calib_matrix = load_calibration_matrix(os.path.join(img_dir, 'calib.txt'))\n",
    "    K = calib_matrix / downscale_factor\n",
    "\n",
    "    feature_params = dict(maxCorners=100,\n",
    "                          qualityLevel=0.3,\n",
    "                          minDistance=7,\n",
    "                          blockSize=7)\n",
    "\n",
    "    lk_params = dict(winSize=(15, 15),\n",
    "                     maxLevel=2,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    prev_image = cv2.imread(os.path.join(img_dir, image_list[0]))\n",
    "    prev_gray = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
    "\n",
    "    total_points = np.zeros((1, 3))\n",
    "    total_colors = np.zeros((1, 3))\n",
    "\n",
    "    pose_array = []\n",
    "\n",
    "    for i in tqdm(range(1, len(image_list))):\n",
    "        image = cv2.imread(os.path.join(img_dir, image_list[i]))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None, **lk_params)\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        E, _ = cv2.findEssentialMat(good_old, good_new, K, cv2.RANSAC, 0.999, 1.0, None)\n",
    "        _, R, t, _ = cv2.recoverPose(E, good_old, good_new, K)\n",
    "\n",
    "        if i != 1:\n",
    "            F, _ = cv2.findFundamentalMat(good_old, good_new, cv2.RANSAC)\n",
    "            _, H1, H2 = cv2.stereoRectifyUncalibrated(good_old, good_new, F, (prev_gray.shape[1], prev_gray.shape[0]))\n",
    "\n",
    "            points, _ = cv2.correctMatches(F, good_old.reshape(-1, 1, 2), good_new.reshape(-1, 1, 2))\n",
    "            points = points.squeeze()\n",
    "\n",
    "            common_points_1, common_points_2 = find_common_points(good_old, points)\n",
    "            common_points_2 = common_points_2[:common_points_1.shape[0]]\n",
    "\n",
    "            good_new = good_new[common_points_2]\n",
    "            good_old = good_old[common_points_1]\n",
    "\n",
    "        _, points_3d = cv2.triangulatePoints(np.eye(3, 4), np.hstack((R, t)), good_old.T, good_new.T)\n",
    "        points_3d = points_3d / points_3d[3]\n",
    "\n",
    "        if enable_bundle_adjustment and i != 1:\n",
    "            _, points_3d = cv2.correctMatches(F, good_old.reshape(-1, 1, 2), points_3d[:3].T)\n",
    "            points_3d = points_3d.squeeze()\n",
    "\n",
    "        _, rot_matrix, tran_matrix, _ = cv2.recoverPose(E, good_old, good_new, K)\n",
    "\n",
    "        if enable_bundle_adjustment:\n",
    "            pose_array.extend([pose.ravel() for pose in np.hstack((rot_matrix, tran_matrix.reshape(-1, 1)))])\n",
    "\n",
    "        _, rot_matrix, tran_matrix, _ = cv2.solvePnPRansac(points_3d, good_new, K, None)\n",
    "        transform_matrix = np.hstack((rot_matrix, tran_matrix))\n",
    "\n",
    "        if enable_bundle_adjustment:\n",
    "            pose_array.extend([pose.ravel() for pose in transform_matrix])\n",
    "\n",
    "        pose_array.extend([pose.ravel() for pose in transform_matrix])\n",
    "\n",
    "        _, rot_matrix, tran_matrix, _ = cv2.solvePnPRansac(points_3d, good_new, K, None)\n",
    "        transform_matrix = np.hstack((rot_matrix, tran_matrix))\n",
    "\n",
    "        if enable_bundle_adjustment:\n",
    "            pose_array.extend([pose.ravel() for pose in transform_matrix])\n",
    "\n",
    "        pose_array.extend([pose.ravel() for pose in transform_matrix])\n",
    "\n",
    "        if enable_bundle_adjustment and i != 1:\n",
    "            opt = cv2.fisheye_CALIB_RATIONAL_MODEL\n",
    "            _, points_3d = cv2.fisheye.triangulatePoints(H1, H2, good_old.T, good_new.T)\n",
    "            points_3d = points_3d / points_3d[3]\n",
    "\n",
    "            _, points_3d = cv2.correctMatches(F, good_old.reshape(-1, 1, 2), points_3d[:3].T)\n",
    "            points_3d = points_3d.squeeze()\n",
    "\n",
    "            points_3d, _, _ = cv2.fisheye.calibrate([points_3d], None, (image.shape[1], image.shape[0]), K, None, None, None, flags=opt)\n",
    "            points_3d = points_3d.squeeze()\n",
    "\n",
    "        pose_array.extend([pose.ravel() for pose in np.hstack((rot_matrix, tran_matrix.reshape(-1, 1)))])\n",
    "        total_points = np.vstack((total_points, points_3d))\n",
    "\n",
    "        points_left = np.array(good_new, dtype=np.int32)\n",
    "        color_vector = np.array([image[l[1], l[0]] for l in points_left])\n",
    "        total_colors = np.vstack((total_colors, color_vector))\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "    if enable_bundle_adjustment:\n",
    "        K = K / downscale_factor\n",
    "        ret, K, D, rvecs, tvecs = cv2.calibrateCamera(total_points.reshape(-1, 1, 3), total_colors.reshape(-1, 1, 3), (image.shape[1], image.shape[0]), K, None, None)\n",
    "        print(\"Bundle adjustment completed.\")\n",
    "\n",
    "    return total_points, total_colors, pose_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    data_dir = \"data\\\\set1\"\n",
    "    downscale_factor = 2.0\n",
    "    enable_bundle_adjustment = True\n",
    "\n",
    "    total_points, total_colors, pose_array = process_images(data_dir, downscale_factor, enable_bundle_adjustment)\n",
    "\n",
    "    print(\"Printing to .ply file\")\n",
    "    print(total_points.shape, total_colors.shape)\n",
    "\n",
    "    out_points = total_points * 200\n",
    "    out_colors = total_colors\n",
    "\n",
    "    mean = np.mean(out_points, axis=0)\n",
    "    scaled_verts = out_points - mean\n",
    "    dist = np.sqrt(np.sum(scaled_verts ** 2, axis=1))\n",
    "    indx = np.where(dist < np.mean(dist) + 300)\n",
    "    verts = np.hstack([out_points[indx], out_colors[indx]])\n",
    "\n",
    "    ply_header = '''ply\n",
    "        format ascii 1.0\n",
    "        element vertex %(vert_num)d\n",
    "        property float x\n",
    "        property float y\n",
    "        property float z\n",
    "        property uchar red\n",
    "        property uchar green\n",
    "        property uchar blue\n",
    "        end_header\n",
    "        '''\n",
    "\n",
    "    ply_path = os.path.join(data_dir, 'set1.ply')\n",
    "    with open(ply_path, 'w') as f:\n",
    "        f.write(ply_header % dict(vert_num=len(verts)))\n",
    "        np.savetxt(f, verts, '%f %f %f %d %d %d')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
